[
  {
    "objectID": "dataviztwo.html",
    "href": "dataviztwo.html",
    "title": "Greatest Albums",
    "section": "",
    "text": "This data set from TidyTuesday originates from a Google Sheet compiled by Chris Eckert. It compares Rolling Stone’s “500 Greatest Albums of All Time” lists from 2003, 2012, and 2020 and includes information on each album’s name, genre, release year, 2003/2012/2020 rank, the artist’s name, birth year, gender, and more. This analysis looks at the trend in the production of the “greatest” albums over time. Which years were the most fruitful? Are artists getting worse at producing incredible albums?\n\n\nShow the code\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 19)\n\nrolling_stone &lt;- tuesdata$rolling_stone\n\nrolling_stone_df &lt;- rolling_stone %&gt;% \n  group_by(release_year) %&gt;% \n  summarize(num_per_year = n_distinct(album))\n\nggplot(rolling_stone_df, aes(x = release_year, y = num_per_year)) +\n  geom_point(color = \"cadetblue\") +\n  geom_line(color = \"cadetblue\") +\n  labs(\n    title = \"Rolling Stone's Greatest Albums of All Time\",\n    x = \"Release Year\",\n    y = \"Number of Albums Included in Top 500 Ranking\",\n  ) \n\n\n\n\n\n\n\n\n\nSource:\nRolling Stone Album Rankings: Tidy Tuesday Data from 2024-05-07\nDalla Riva, C., & Daniels, M. (n.d.). WHAT MAKES AN ALBUM THE GREATEST OF ALL TIME? The Pudding. https://pudding.cool/2024/03/greatest-music/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emma’s Site",
    "section": "",
    "text": "Hi there! This is my first Quarto website, on which you can find some things I’ve been working on in my Intro to Data Science class. Feel free to check out my About page to find out more :)"
  },
  {
    "objectID": "datavizone.html",
    "href": "datavizone.html",
    "title": "Musicians in the US",
    "section": "",
    "text": "This data is from TidyTuesday and is sourced from the National Endowment for the Arts. It gives state-level estimates for the total number of artists and for each individual type of artist in the workforce, covering 2015-2019. This analysis examines the total number of workers in the music industry specifically (musicians, music directors, and composers) and compares the totals across races.\n\n\nShow the code\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load('2022-09-27')\ntuesdata &lt;- tidytuesdayR::tt_load(2022, week = 39)\n\nartists &lt;- tuesdata$artists\n\nartists2 &lt;- artists %&gt;%\n  mutate(Music_Industry = str_detect(type, \"Music\")) %&gt;%\n  filter(Music_Industry == TRUE) %&gt;%\n  group_by(race) %&gt;%\n  summarize(total_musicians = sum(artists_n, na.rm = TRUE)) %&gt;% \n  mutate(race = fct_reorder(race, total_musicians, .desc = TRUE))\n\n\nggplot(artists2, aes(x = race, y = total_musicians)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Distribution of Music Industry Professionals Across Races in the US\",\n    x = \"Race\",\n    y = \"Number working as Musicians, Music Directors, or Composers\",\n  )\n\n\n\n\n\n\n\n\n\nSource:\nArtists in the USA: Tidy Tuesday Data from 2022-09-27\nArtists in the Workforce: National and State Estimates for 2015-2019. (July 2022). National Endowment for the Arts. https://www.arts.gov/impact/research/arts-data-profile-series/adp-31."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Emma. For the sake of anonymity, I’ll leave out my last name.\nThe data visualizations you can find on the website both focus on music… I love music!\nMy favourite albums right now include the following:\n\n“little oblivions” by julien baker\n“the 1975 (deluxe version)” by the 1975\n“divinely uninspired to a hellish extent” by lewis capaldi\n“21” by adele\n“the record” by boygenius\n“punisher” by phoebe bridgers\n“home video” by lucy dacus \n“take the sadness out of saturday night” by bleachers"
  },
  {
    "objectID": "textanalysis.html",
    "href": "textanalysis.html",
    "title": "Text Analysis",
    "section": "",
    "text": "This data set contains 20,000 letters written in to Dear Abby, and was used in The Pudding essay “30 Years of American Anxieties: What 20,000 letters to an advice columnist tell us about what—and who—concerns us most.” The data contains letters published from 1985 to 2017.\n\n\nShow the code\nlibrary(tidyverse)\n\ndearabby &lt;- read_csv(\"https://raw.githubusercontent.com/the-pudding/data/master/dearabby/raw_da_qs.csv\")\n\ndearabby1 &lt;- dearabby %&gt;% \n  mutate(title = str_to_lower(title)) %&gt;% \n  group_by(year) %&gt;% \n  summarize(\n    mom = sum(str_count(title, \"mom*.\"), na.rm = TRUE), \n    dad = sum(str_count(title, \"dad*.\"), na.rm = TRUE))\n\nggplot(dearabby1, aes(year)) +\n  geom_line(aes(y = mom, color = \"Mom\")) +\n  geom_line(aes(y = dad, color = \"Dad\")) +\n  labs(\n    title = \"Mention of Mom and Dad in 'Dear Abby' Column Titles Over Time\",\n    x = \"Year\",\n    y = \"Frequency\",\n  )\n\n\n\n\n\n\n\n\n\n\nThis data visualization illustrates the frequency of use of “mom” and “dad” in the Dear Abby letters between 1985 and 2017. The plot demonstrates that both words have been employed more frequently over the course of the 30 years, despite the fact that the number of letters published per year remained constant (approximately one letter per day). Notably, the mention of “mom” and “dad” vary with one another, though “mom” reliably appears more often. The plot might suggest that writers have become more concerned with issues relating to/involving their parents in over the course of the past thirty years.\n\n\nShow the code\nlibrary(tidyverse)\n\ndearabby2 &lt;- dearabby %&gt;%\n  mutate(self_verbs = str_extract_all(question_only, \"(?&lt;=i )\\\\w+\")) %&gt;% \n  unnest(self_verbs) %&gt;%\n  group_by(self_verbs) %&gt;%\n  summarize(count = n()) %&gt;% \n  filter(str_detect(self_verbs, \"(want$|wish$|hope$|pray$|expect$|beg$|require$)\")) %&gt;%\n  arrange(count)\n\nggplot(dearabby2, aes(x = self_verbs, y = count)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Mention of Desire Verbs in 'Dear Abby' Questions\",\n    x = \"Frequency of Use\",\n    y = \"Expression of Desire\",\n  )\n\n\n\n\n\n\n\n\n\nThis data visualization seeks to model the use of verbs expressing personal desire. The top six verbs expressing desire (begging, expecting, hoping, praying, wanting, and wishing) were selected, and the frequency of their occurrence was compared. The only instances in which these occurrences were counted was in direct reference to the self (“I …”). This suggests that a far greater proportion of expressed their desires in terms of wanting something compared to hoping or praying for something.\n\n\nShow the code\ndearabby3 &lt;- dearabby %&gt;% \n  mutate(wants = str_detect(question_only, \"\\\\bi want\\\\b\")) %&gt;% \n  filter(wants == TRUE) %&gt;% \n  group_by(year) %&gt;% \n  summarize(want_count = sum(wants))\n\nggplot(dearabby3, aes(x = year, y = want_count)) +\n  geom_point(color = \"deepskyblue3\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray\") +\n  labs(\n    title = \"Mention of 'Wanting' in 'Dear Abby' Questions Over Time\",\n    x = \"Year\",\n    y = \"Expression of Wants\",\n  )\n\n\n\n\n\n\n\n\n\nThis data visualization further investigates the use of the phrase “I want”, which was found to be the most common expression of desire in the previous plot. The present analysis compares the frequency of the occurrence of this phrase over the course of the thirty years. The plot suggests that there is a weak positive correlation between time and expression of “wanting”.\nSource:\nDear Abby: The Pudding on GitHub (2018).\nBlinderman, I., Ralph, C., & Samora, R. (2018, November). 30 years of American anxieties. The Pudding. https://pudding.cool/2018/11/dearabby/."
  },
  {
    "objectID": "PermutationTest.html",
    "href": "PermutationTest.html",
    "title": "Permutation Test",
    "section": "",
    "text": "In this project, I am examining the TidyTuesday dataset on “National Park Visits” and testing the hypothesis that yearly visitor numbers in national parks across the country correlate with the price of gas in that year. The original data consists of three CSV files, including info on national park visitors from 1904 to 2016, state populations, annual gas prices from 1929 to 2015 adjusted for inflation, and locations. In the following analysis, I plan to explore the relationship between national park visitation and gas price, hypothesizing that a higher price might correlate with lower visitor rates, since people might be less motivated to drive and thus spend more money on gas. Of course, this hypothesis will presumably be difficult to demonstrate, due to the broad scope and limited specificity of the data. For my analysis, I plan to compare visitor rates with gas prices from the years 1929 to 2015. I will assign the gas prices adjusted to the 2015 inflation rate to the categories “low” or “high” depending on whether they exceed the threshold of $2.04 (the median of gas prices). Then, I will calculate the mean number of total visitors to all national parks for high price years and low gas price years, and plot the results on a bar graph. Ultimately, I will generate a null sampling distribution in order to examine to what extent the difference between high and low price years is likely due to the gas price variable, or whether the results are likely to be random.\n\n\nShow the code\nlibrary(dplyr)\nlibrary(tidyverse)\n\npark_visits &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-09-17/national_parks.csv\")\n\ngas_price &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-09-17/gas_price.csv\")\n\n#cleaning the park visits dataframe\n\npark_visits_revised &lt;- park_visits |&gt;\n  select(year, unit_name, visitors) |&gt;\n  group_by(year) |&gt;\n  summarize(total_visitors = sum(visitors)) |&gt;\n  filter(year &gt;= \"1929\", year &lt;= \"2015\") |&gt;\n  mutate(year = as.numeric(year))\n\n#cleaning the gas price dataframe\n\n# gas_price |&gt; \n#   summarize(median = median(gas_constant))\n\ngas_price_revised &lt;- gas_price |&gt;\n  mutate(gas_price = case_when(\n    gas_constant &lt; 2.04 ~ \"low\",\n    TRUE ~ \"high\",\n  )) |&gt;\n  select(year, gas_price) |&gt;\n  filter(year &gt;= \"1929\", year &lt;= \"2015\")\n\n#joining both dataframes\n\njoined_data &lt;- full_join(park_visits_revised, gas_price_revised, by = \"year\")\n\n#initial result calculations & graphing\n\nmeans_calculated &lt;- joined_data |&gt; \n  group_by(gas_price) |&gt; \n  summarize(ave_visitors = mean(total_visitors))\n\nggplot(data = means_calculated, aes(x = gas_price, y = ave_visitors)) + \n  geom_bar(stat = \"identity\", fill = \"cornflowerblue\") +\n  geom_text(aes(label = ave_visitors), stat = \"identity\", vjust = -0.5) +\n  labs(title = \"Difference in Yearly National Park Visitors Based on Annual Gas Price\", x = \"Annual Gas Price\", y = \"Yearly National Park Visitors\") \n\n\n\n\n\n\n\n\n\nThe plot above displays the mean of the total national park visitors per year for the high gas price ( &gt;= $2.04) and low gas price (&lt; $2.04) conditions. During years with high gas prices, there were upwards of 124 million visitors per year on average. During years with low gas prices, however, there were more than 184 million visitors per year on average, approximately 60 million more than in the low price condition.\n\n\nShow the code\n#permutation test\n\nperm_data &lt;- function(rep){\n  joined_data |&gt; \n    select(total_visitors, gas_price) |&gt; \n    mutate(gas_perm = sample(total_visitors, replace = FALSE)) |&gt; \n    group_by(gas_price) |&gt; \n    summarize(obs_ave = mean(total_visitors),\n              perm_ave = mean(gas_perm)) |&gt; \n    summarize(obs_ave_diff = diff(obs_ave),\n              perm_ave_diff = diff(perm_ave),\n              rep = rep)\n}\n\nset.seed(47)\nperm_stats &lt;- map(c(1:700), perm_data) |&gt; \n  list_rbind()\n\nperm_stats |&gt; \n  ggplot(aes(x = perm_ave_diff)) + \n  geom_histogram(fill = \"cornflowerblue\") + \n  geom_vline(aes(xintercept = obs_ave_diff), color = \"deeppink4\") +\n  labs(title = \"Null Sampling Distribution of Mean Difference in Visitors\", x = \"Difference in Means\", y = \"Count\")\n\n\n\n\n\n\n\n\n\nShow the code\n#calculating p-value\n\nperm_stats |&gt; \n  summarize(p_val_ave = mean(perm_ave_diff &gt; obs_ave_diff))\n\n\n# A tibble: 1 × 1\n  p_val_ave\n      &lt;dbl&gt;\n1   0.00857\n\n\nThe plot above represents a null sampling distribution created from a 700 permutations of yearly visitor totals being randomly assigned to the high or low gas price condition and the difference in means between the two conditions being calculated. When the difference of ~60 million - as calculated from the observed data - was plotted is on the null sampling distribution, it becomes clear that the observed effect is somewhat unlikely to be randomly caused. In fact, the p-value of 0.008 calculated in the data frame above suggests that there is moderate evidence against the null model. As such, we could accept the hypothesis that years with higher gas prices have seen lower national park attendance in the past. However, one must of course be cautious about not reading too much into these results, since the data is highly generalized, and a variety of other factors (such as economic stability, national park popularity, and willingness to go on trips) may have played a role in the data.\nSource:\nTidy Tuesday. (2019, September 17). National Park Visits. GitHub. https://github.com/rfordatascience/tidytuesday/tree/main/data/2019/2019-09-17. Originally sourced from dataisplural/data.world."
  },
  {
    "objectID": "Ethics.html",
    "href": "Ethics.html",
    "title": "Ethics: Data & Power",
    "section": "",
    "text": "Pennsylvania’s Allegheny County, in which Pittsburgh is situated, has implemented a predictive tool for child neglect detection since August of 2016 [1]. The algorithm, called the Allegheny Family Screening Tool (AFST) is utilized by the child welfare agency in the county to assess the gravity of received reports of child neglect and to make decisions about which families should be further investigated [2]. Using data on family Medicaid and substance abuse records, as well as jail and probation history, the AFST assigns risk scores to flagged children which, in turn, are used to decide whether a full investigation (and potentially foster-care placement) is advisable [1]. More specifically, the tool is designed to predict how likely it is that a child will need to be removed from their home in the long-term [2].\nAs such, the algorithm represents a somewhat automated approach to a decision that would usually be made on an individual basis—data science is utilized to predict risk of child neglect based on contextual factors. The approach has plausible benefits but simultaneously raises various ethical concerns about privacy and bias. One such ethical concern is the disproportionate distribution of risk scores across race. Even though the AFST doesn’t directly use any data on race, the measures it does use skew results due to historical inequalities and over-surveillance of poor, Black, and marginalized families [1]. Additionally, there was a technical glitch in the tool for more than two years where some children got inaccurately high or low scores [1]. Ethical concerns extend past the output of the algorithm itself and are founded on the way in which the AFST results are used. Overall, there isn’t much transparency—and much less consent—about the fact that data from multiple government systems are being analyzed to affect a family’s child welfare investigation [1]. As a result, the combination of algorithmic mistakes, built-in biases, and insufficient transparency prompt an ongoing debate about the ethics of the AFST [2]. In the following paragraphs, I will assess the extent to which the use of the AFST in Allegheny County adheres to or diverges from four different components of the Data Values and Principles Manifesto [3].\nThe first principle in the Manifesto reads “Use data to improve life for our users, customers, organizations, and communities” [3]. This principle is important for ensuring that data science is used for making a positive impact, rather than a bad one. The issue is, of course, that what is considered to be “positive” can often be subjective. The interests of customers, for example, often seem to be at odds with the interests of sellers. Whether this principle adopts a utilitarian view of the greatest possible good is unclear, but it may be said that the AFST certainly seems to aim for the improvement of the life of the communities it interacts with. After all, it was designed to help the child welfare agency in Allegheny County make more reliably accurate decisions about whether a child is actually in danger of neglect [1]. By expediting the process of evaluating reports of child neglect, the agency is able to process more reports at a faster rate, so that it can intervene sooner and more reliably. A comprehensive evaluation of the AFST by Stanford’s Professor Goldhaber-Fiebert found that “Implementation of the AFST and associated policies increased accuracy for children screened-in for investigation” [4].\nThe 7th principle in the Manifesto highlights the need to “recognize and mitigate bias in ourselves and in the data we use” [3]. There are countless forms of biases that can occur in collected data, which consequently skew the results drawn from data. Biased results can have severe and devastating repercussions, from simply supporting incorrect opinions to drastically affecting the communities that the data implicates. Completely eliminating bias from data is often nearly impossible, but measures should always be taken to ensure that information is interpreted fairly and used ethically. This, it can be argued, is not necessarily the case for the AFST. Researchers at Carnegie Mellon University, for example, found that during early years (Aug 2016–May 2018) the tool flagged a higher percentage of Black children for “mandatory” investigations (32.5%) than white children (20.8%) [1]. Such skews in the data could have led to disproportionate quantities of Black families being separated from their children, a terrible circumstance if not properly justified.\nThe 10th principle of the Manifesto reads as follows: “Respect and invite fair criticism while promoting the identification and open discussion of errors, risks, and unintended consequences of our work” [3]. This is a key aspect of ethical data science, since errors can be missed by even the most rigorous of evaluations. Being open to criticisms and the identification of errors from others is vital to ensuring that the conclusions drawn from the data are as ethical as possible. Allegheny County’s child welfare agency seems to do a relatively good job at this. On their website, which contains a comprehensive description of the AFST and its use, they include links and responses to various criticisms of their algorithm [2]. Rather than ignoring or shutting down any pessimistic or critical views of their program, they engage with them in a meaningful and fair manner. In a statement released after the publication of the article Associated Press (AP) article “An algorithm that screens for child neglect raises concerns”, they provide detailed responses that address the main criticisms described in the article [5].\nFinally, I will go back to the 9th principle of the Manifesto, which cautions data scientists to “consider carefully the ethical implications of choices [they] make when using data, and the impacts of [their] work on individuals and society” [3]. As mentioned above, the misuse of data can have grave consequences, so it is vital that data scientists are aware of the ethical considerations that accompany their work. Despite the concerns raised above, it seems that the Allegheny County child welfare agency and the developers of the AFST seem to be well aware of the gravity of their roles and decisions. One of the most important aspects of their approach, one might argue, is the fact that they only use the AFST algorithm as a support for decision-making, and is exclusively used in hotline call screenings—not family court or removal decisions [5]. This is described in detail in the statement mentioned above, in which it is stated that “the AFST was not designed, nor has there ever been a discussion of using it, to autonomously make […] screening decisions” [5]. The algorithm is purely meant to assist with decisions, not to make them independently, which demonstrates that Allegheny County is not failing to take the gravity of their actions seriously.\nAll of the concerns discussed above matter because the well-being of thousands of families and their children across the county of Allegheny (and across the nation if such algorithms are adopted in other regions) are at stake. The data science principles addressed provide a small insight into why it is vital to utilize data carefully and ethically—a concern that is only exacerbated by the sensitive situation that is child neglect. The ethical violations that are occurring seem to be largely unintentional (not in the interest of profit, for example), but might be the result of cutting corners in the interest of efficiency. Such shortcomings might provide small benefits to the child welfare agency but can have devastating consequences for the affected families and children.\nBibliography:\n[1] Ho, S., & Burke, G. (2022, April 29). An algorithm that screens for child neglect raises concerns. Pulitzer Center. https://pulitzercenter.org/stories/algorithm-screens-child-neglect-raises-concerns\n[2] Allegheny County Department of Human Services. (n.d.). Allegheny Family Screening Tool: Predictive risk modeling in child welfare in Allegheny County. Retrieved November 12, 2025, from https://www.alleghenycounty.us/Services/Human-Services-DHS/DHS-News-and-Events/Accomplishments-and-Innovations/Allegheny-Family-Screening-Tool\n[3] Data Practices. (n.d.). Manifesto for Data Practices: Data values and principles. Retrieved November 12, 2025, from https://datapractices.org/manifesto/\n[4] Goldhaber-Fiebert, J. D., & Prince, L. (2019, March). Impact evaluation of a predictive risk modeling tool for Allegheny County’s child welfare office (Report No. 16-ACDHS-26). Allegheny County Department of Human Services. https://www.alleghenycounty.us/files/assets/county/v/1/services/dhs/documents/allegheny-family-screening-tool/impact-evaluation-from-16-acdhs-26_predictiverisk_package_050119_final-6.pdf\n[5] Allegheny County Department of Human Services. (2022, May 9). DHS response to AP article “An algorithm that screens for child neglect raises concerns” [PDF]. https://www.alleghenycounty.us/files/assets/county/v/1/services/dhs/documents/allegheny-family-screening-tool/dhs-response-to-ap-article_algorithm-that-screens-for-child-neglect.pdf"
  },
  {
    "objectID": "SQL.html",
    "href": "SQL.html",
    "title": "SQL",
    "section": "",
    "text": "The Stanford Open Policing Project works toward closing the gaping holes in police traffic stop data across the United States. The project gathers and enables access to standardized data on individual traffic stops by publishing individual data sets for various places across the US, which include information on stop date and time, location, driver race, gender and age, as well as searches.\n\n\nShow the code\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\n\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n\nThe goal of my first SQL query was to assess the trends in gender across both pedestrian and vehicle stops in Los Angeles. The dataset ranges from December 2009 to June 2018.\n\n\nShow the code\nSELECT\n    type,\n    subject_sex,\n    COUNT(*) AS stop_count\nFROM ca_los_angeles_2020_04_01\nWHERE type IS NOT NULL\nGROUP BY type, subject_sex\nORDER BY type, subject_sex;\n\n\nThe stacked bar plot below demonstrates the vast difference in number of traffic stops of male subjects compared to female subjects in Los Angeles in the given time frame. It is also interesting to note that this difference applies for both pedestrian and vehicular stops. Overall, over 2 million more males were stopped than females. It might be interesting to think about what this implies for either biases in police stop selection, or for differences in traffic law compliance or recklessness across genders.\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(scales)\n\nstop_type_gender |&gt; \n  ggplot(aes(x = subject_sex, y = stop_count, fill = type)) + \n  geom_col(position = \"stack\") +\n  labs(title = \"Traffic Stops by Gender in Los Angeles Dec 2009 - Jun 2018\", \n       x = \"Subject Gender\", \n       y = \"Stop Count\") +\n  scale_fill_manual(values = c(\"cornflowerblue\", \"navyblue\")) +\n  scale_y_continuous(labels = comma)\n\n\n\n\n\n\n\n\n\nMy next SQL query aimed to investigate the trends in traffic stops from the perspective of the 24-hour day. In addition to overall stops, I also wanted to examine potential trends in contraband found or searches conducted. This is because I hypothesized that there would be a greater number of reckless or non-law-abiding drivers/pedestrians later in the evening than at other times of the day. For example, it could be more likely that someone drives under the influence late at night compared to at noon. The data examined in this query was taken from New Orleans between December 2009 and July 2018.\n\n\nShow the code\nSELECT\n    HOUR(time) AS hour,\n    SUM(search_conducted = 1) AS searches,\n    SUM(contraband_found = 1) AS contraband,\n    SUM(1) AS stop_count\nFROM la_new_orleans_2020_04_01\nWHERE type IS NOT NULL\nGROUP BY hour\nORDER BY hour;\n\n\nThe line plot below reveals trends in traffic stops at different hours of the day. Such trends are most visible in the overall stop count, but are also reflected in the searches conducted and the contraband found, as it would be expected that the latter correlate with the former. As hypothesized, stop counts are greater in the late evening and night, with the most significant dip around 6 in the morning. The number of searches conducted also slightly increases towards the night and goes down in the morning.\n\n\nShow the code\nlibrary(dplyr)\nlibrary(tidyr)\n\nlong_df &lt;- stop_time %&gt;%\n  pivot_longer(\n    cols = c(searches, contraband, stop_count),\n    names_to = \"metric\",\n    values_to = \"value\"\n  )\n\nlong_df |&gt; \n  ggplot(aes(x = hour, y = value, color = metric)) + \n  geom_line() +\n  geom_point() +\n  scale_color_manual(values = c(\"contraband\" = \"cornflowerblue\", \n                                \"searches\" = \"navyblue\", \n                                \"stop_count\" = \"cadetblue\")) +\n  labs(title = \"Traffic Stops by Time of Day in New Orleans Dec 2009 - Jul 2018\", \n       x = \"Hour\", \n       y = \"Count\")\n\n\n\n\n\n\n\n\n\nMy final SQL query explored the role of age in traffic stops, differentiating between subject gender. Here, I looked at the data from Nashville between December 2009 and March 2019.\n\n\nShow the code\nSELECT\n    subject_age,\n    subject_sex,\n    COUNT(*) AS stop_count\nFROM tn_nashville_2020_04_01\nWHERE subject_age IS NOT NULL AND subject_sex IS NOT NULL\nGROUP BY subject_age, subject_sex\nORDER BY subject_age;\n\n\nThe line plot below illustrates the data for overall traffic stops by age for the given time frame in Nashville. As might be expected, younger people (presumably more inexperienced and/or reckless) represent the greatest number of subjects in traffic stops, such that the plot peaks around 21 for both genders. Notably, as demonstrated in the first plot, a greater number of the subjects are male.\n\n\nShow the code\ngender_stops |&gt; \n  ggplot(aes(x = subject_age, y = stop_count, color = subject_sex)) + \n  geom_line() +\n  scale_color_manual(values = c(\"female\" = \"cornflowerblue\", \n                                \"male\" = \"navyblue\")) +\n  labs(title = \"Traffic Stops by Subject Age and Gender in Nashville Dec 2009 - Mar 2019\", \n       x = \"Subject Age\", \n       y = \"Stop Count\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ndbDisconnect(con_traffic, shutdown = TRUE)\n\n\nOverall, these queries into the Stanford Open Policing Project reveal trends in gender, age, and time of day that correlate with greater or lower numbers of traffic stops. Since each plot only explores the data from one region each, it would be interesting the merge the complete selection of data sets for a more comprehensive overview.\nSource:\nStanford Open Policing Project\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, D. Jenson, A. Shoemaker, V. Ramachandran, P. Barghouty, C. Phillips, R. Shroff, and S. Goel. “A large-scale analysis of racial disparities in police stops across the United States”. Nature Human Behaviour, Vol. 4, 2020."
  },
  {
    "objectID": "FinalPresentation.html#first-slide",
    "href": "FinalPresentation.html#first-slide",
    "title": "Rolling Stone’s Top 500: A Shiny App",
    "section": "First Slide",
    "text": "First Slide\nThis data set from TidyTuesday originates from a Google Sheet compiled by Chris Eckert. It compares Rolling Stone’s “500 Greatest Albums of All Time” lists from 2003, 2012, and 2020 and includes information on each album’s name, genre, release year, 2003/2012/2020 rank, the artist’s name, birth year, gender, and more. This analysis looks at the trend in the production of the “greatest” albums over time. Which years were the most fruitful? Are artists getting worse at producing incredible albums?\n\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 19)\n\nrolling_stone &lt;- tuesdata$rolling_stone\n\nrolling_stone_df &lt;- rolling_stone |&gt; \n  group_by(release_year) |&gt; \n  summarize(num_per_year = n_distinct(album))\n\nggplot(rolling_stone_df, aes(x = release_year, y = num_per_year)) +\n  geom_point(color = \"cadetblue\") +\n  geom_line(color = \"cadetblue\") +\n  labs(\n    title = \"Rolling Stone's Greatest Albums of All Time\",\n    x = \"Release Year\",\n    y = \"Number of Albums Included in Top 500 Ranking\",\n  ) \n\n\nSource:\nRolling Stone Album Rankings: Tidy Tuesday Data from 2024-05-07\nDalla Riva, C., & Daniels, M. (n.d.). WHAT MAKES AN ALBUM THE GREATEST OF ALL TIME? The Pudding. https://pudding.cool/2024/03/greatest-music/."
  },
  {
    "objectID": "FinalPresentation.html#second-slide",
    "href": "FinalPresentation.html#second-slide",
    "title": "Rolling Stone’s Top 500: A Shiny App",
    "section": "Second Slide",
    "text": "Second Slide"
  },
  {
    "objectID": "FinalPresentation.html#the-data",
    "href": "FinalPresentation.html#the-data",
    "title": "Rolling Stone’s Top 500: A Shiny App",
    "section": "The Data",
    "text": "The Data\nThis data set from TidyTuesday originates from a Google Sheet compiled by Chris Eckert. It compares Rolling Stone’s “500 Greatest Albums of All Time” lists from 2003, 2012, and 2020 and includes information on each album’s name, genre, release year, 2003/2012/2020 rank, the artist’s name, birth year, gender, and more. This analysis looks at the trend in the production of the “greatest” albums over time. Which years were the most fruitful? Are artists getting worse at producing incredible albums?\n\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 19)\n\nrolling_stone &lt;- tuesdata$rolling_stone\n\ncolnames(rolling_stone)\n\n [1] \"sort_name\"                \"clean_name\"              \n [3] \"album\"                    \"rank_2003\"               \n [5] \"rank_2012\"                \"rank_2020\"               \n [7] \"differential\"             \"release_year\"            \n [9] \"genre\"                    \"type\"                    \n[11] \"weeks_on_billboard\"       \"peak_billboard_position\" \n[13] \"spotify_popularity\"       \"spotify_url\"             \n[15] \"artist_member_count\"      \"artist_gender\"           \n[17] \"artist_birth_year_sum\"    \"debut_album_release_year\"\n[19] \"ave_age_at_top_500\"       \"years_between\"           \n[21] \"album_id\"                \n\n\n\nSource:\nRolling Stone Album Rankings: Tidy Tuesday Data from 2024-05-07\nDalla Riva, C., & Daniels, M. (n.d.). WHAT MAKES AN ALBUM THE GREATEST OF ALL TIME? The Pudding. https://pudding.cool/2024/03/greatest-music/."
  },
  {
    "objectID": "FinalPresentation.html#data-wrangling",
    "href": "FinalPresentation.html#data-wrangling",
    "title": "Rolling Stone’s Top 500: A Shiny App",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nrolling_stone_df &lt;- rolling_stone |&gt; \n  group_by(release_year) |&gt; \n  summarize(num_per_year = n_distinct(album))\n\nggplot(rolling_stone_df, aes(x = release_year, y = num_per_year)) +\n  geom_point(color = \"cadetblue\") +\n  geom_line(color = \"cadetblue\") +\n  labs(\n    title = \"Rolling Stone's Greatest Albums of All Time\",\n    x = \"Release Year\",\n    y = \"Number of Albums Included in Top 500 Ranking\",\n  ) \n\n\nSource:\nRolling Stone Album Rankings: Tidy Tuesday Data from 2024-05-07\nDalla Riva, C., & Daniels, M. (n.d.). WHAT MAKES AN ALBUM THE GREATEST OF ALL TIME? The Pudding. https://pudding.cool/2024/03/greatest-music/."
  },
  {
    "objectID": "FinalPresentation.html#original-data-visualization",
    "href": "FinalPresentation.html#original-data-visualization",
    "title": "Rolling Stone’s Top 500: A Shiny App",
    "section": "Original Data Visualization",
    "text": "Original Data Visualization\n\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 19)\n\nrolling_stone &lt;- tuesdata$rolling_stone\n\nrolling_stone_df &lt;- rolling_stone |&gt; \n  group_by(release_year) |&gt; \n  summarize(num_per_year = n_distinct(album))\n\nggplot(rolling_stone_df, aes(x = release_year, y = num_per_year)) +\n  geom_point(color = \"cadetblue\") +\n  geom_line(color = \"cadetblue\") +\n  labs(\n    title = \"Rolling Stone's Greatest Albums of All Time\",\n    x = \"Release Year\",\n    y = \"Number of Albums Included in Top 500 Ranking\",\n  )"
  },
  {
    "objectID": "FinalPresentation.html#rolling-stones-500-greatest-albums-of-all-time",
    "href": "FinalPresentation.html#rolling-stones-500-greatest-albums-of-all-time",
    "title": "Rolling Stone’s Top 500: A Shiny App",
    "section": "Rolling Stone’s 500 Greatest Albums of All Time",
    "text": "Rolling Stone’s 500 Greatest Albums of All Time\nThis data set from TidyTuesday originates from a Google Sheet compiled by Chris Eckert. It compares Rolling Stone’s “500 Greatest Albums of All Time” lists from 2003, 2012, and 2020 and includes information on each album’s name, genre, release year, 2003/2012/2020 rank, the artist’s name, birth year, gender, and more. This analysis looks at the trend in the production of the “greatest” albums over time. Which years were the most fruitful? Are artists getting worse at producing incredible albums?\n\nlibrary(tidyverse)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 19)\n\nrolling_stone &lt;- tuesdata$rolling_stone\n\ncolnames(rolling_stone)\n\n [1] \"sort_name\"                \"clean_name\"              \n [3] \"album\"                    \"rank_2003\"               \n [5] \"rank_2012\"                \"rank_2020\"               \n [7] \"differential\"             \"release_year\"            \n [9] \"genre\"                    \"type\"                    \n[11] \"weeks_on_billboard\"       \"peak_billboard_position\" \n[13] \"spotify_popularity\"       \"spotify_url\"             \n[15] \"artist_member_count\"      \"artist_gender\"           \n[17] \"artist_birth_year_sum\"    \"debut_album_release_year\"\n[19] \"ave_age_at_top_500\"       \"years_between\"           \n[21] \"album_id\"                \n\n\n\nSource:\nRolling Stone Album Rankings: Tidy Tuesday Data from 2024-05-07\nDalla Riva, C., & Daniels, M. (n.d.). WHAT MAKES AN ALBUM THE GREATEST OF ALL TIME? The Pudding. https://pudding.cool/2024/03/greatest-music/."
  }
]